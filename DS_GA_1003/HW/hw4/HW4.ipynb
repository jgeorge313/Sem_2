{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf8427c",
   "metadata": {},
   "source": [
    "## HW 4 Probabilistic Models\n",
    "## Joby George (jg6615)\n",
    "\n",
    "## Due 3/23/2022\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ac56a",
   "metadata": {},
   "source": [
    "# Problem 1 Prompt:\n",
    "\n",
    "Prove equivalence of ERM for binary classification using logistic loss and probabilistic approach to logistic regression results in the same minimization problem\n",
    "\n",
    "## Problem 1 Answer\n",
    "\n",
    "### MLE Expression for logistic Regression\n",
    "\n",
    "Using slides 45 and 46 from week two of lecture, we know the logistic log function is \n",
    "$$ L(\\theta) = \\frac{1}{n}\\sum_i^{n}log(1 +e^{-m}) \\space and $$\n",
    "\n",
    "where n = the number of data points\n",
    "\n",
    "$$ m =  y_i\\theta^{T} x_i $$\n",
    "\n",
    "Which is equivalent to:\n",
    "\n",
    "$$ L(\\theta) = \\frac{1}{n}\\sum_i^{n}log(1 +e^{-y_i\\theta^{T}x_i}) \\space \\text  where \\space y \\space \\in {-1,1}$$\n",
    "\n",
    "Which is the expression we would like to minimize to minimize empirical risk.\n",
    "\n",
    "### Negative Log-likelihood for logistic regression\n",
    "\n",
    "### Case 1 Y_i = 0, (-1 in MLE Outcome Space) \n",
    "\n",
    "From slide 19 we observe the log-likelihood we would like to maximize:\n",
    "\n",
    "$$NLL = -\\sum_{i}^{n}y_{i} log(f(\\theta^{T}x_{i}))+(1-y_{i})(log(1âˆ’f(\\theta^{T}x_{i})) \\space where \\space y_{i} \\space \\in {0,1} \\space and$$\n",
    "\n",
    "$$f(\\eta) = \\frac{1}{1+e^{\\eta}}$$\n",
    "\n",
    "if $y_{i}$ = 0, we observe this to be:\n",
    "\n",
    "$$NLL = \\sum_{i}^{n}-log(1-f(\\theta^{T}x_{i})) \\space $$\n",
    "\n",
    "\n",
    "plugging  in our logistic link function, if $y_{i}$ = 0 we get:\n",
    "\n",
    "$$NLL = \\sum_{i}^{n}-log(1-\\frac{1}{1+e^{(-\\theta^{T}x_{i})}}) \\space $$\n",
    "\n",
    "setting a common denominator and expanding our logistic, we get: \n",
    "$$NLL = \\sum_{i}^{n}-log(\\frac{1+e^{(-\\theta^{T}x_{i})}-1}{1+e^{(-\\theta^{T}x_{i})}}) \\space $$\n",
    "\n",
    "simplifying this we get \n",
    "$$NLL = \\sum_{i}^{n}-log(\\frac{e^{(-\\theta^{T}x_{i})}}{1+e^{(-\\theta^{T}x_{i})}}) \\space $$\n",
    "\n",
    "multiplying the numerator and denominator by one, expressed as:\n",
    "$$\\frac{e^{(\\theta^{T}x_{i})}}{e^{(\\theta^{T}x_{i})}}$$\n",
    "\n",
    "we get:\n",
    "\n",
    "$$NLL = \\sum_{i}^{n}-log(\\frac{e^{0}}{(1+e^{(-\\theta^{T}x_{i})})   (e^{(\\theta^{T}x_{i})})}) \\space $$\n",
    "\n",
    "\n",
    "which simplifies to \n",
    "$$NLL = \\sum_{i}^{n}-log(\\frac{1}{1+e^{(\\theta^{T}x_{i})}}) \\space $$\n",
    "\n",
    "if we apply the negative sign to the log by taking the reciprocal of it's input, and scale it by a factor of $\\frac{1}{n}$ we end with our final expression:\n",
    "\n",
    "$$NLL = \\frac{1}{n}\\sum_{i}^{n}log(1+e^{\\theta^{T}x_{i}})$$\n",
    "\n",
    "This is equivalent to the MLE when $y_{i}$ = -1:\n",
    "\n",
    "$$ L(\\theta) = \\frac{1}{n}\\sum_i^{n}log(1 +e^{\\theta^{T}x_i}) $$\n",
    "\n",
    "### Case 1 Y_i = 1, (1 in MLE Outcome Space) \n",
    "\n",
    "\n",
    "$$NLL = \\sum_{i}^{n}-log(f(\\theta^{T}x_{i})) \\space $$\n",
    "\n",
    "plugging  in our logistic link function, if $y_{i}$ = 1 we get:\n",
    "\n",
    "$$NLL = \\sum_{i}^{n}-log(\\frac{1}{1+e^{(-\\theta^{T}x_{i})}}) \\space $$\n",
    "\n",
    "if we apply the negative sign to the log by taking the reciprocal of it's input, and scale it by a factor of $\\frac{1}{n}$ we end with our final expression:\n",
    "\n",
    "$$NLL = \\frac{1}{n} \\sum_{i}^{n}log(1+e^{(-\\theta^{T}x_{i})}) \\space $$\n",
    "\n",
    "This is equivalent to the MLE when $y_{i}$ = 1:\n",
    "\n",
    "$$ L(\\theta) = \\frac{1}{n}\\sum_i^{n}log(1 +e^{-\\theta^{T}x_i}) $$\n",
    "\n",
    "### Q.E.D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f65aeb5",
   "metadata": {},
   "source": [
    "# Problem 2 Prompt:\n",
    "\n",
    "Show that the decision boundary of logistic regression is given by x : $x^T$w = 0. Note that the set will not change if we multiply the weights by some constant c."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88da9de",
   "metadata": {},
   "source": [
    "# Problem 3 Prompt:\n",
    "Assume the data are linearly seperable and we have reached a $\\hat{w}$ that perfectly classifies the data. \n",
    "Show that we can always increase the likelihood of the data by multiplying a scalar c on $\\hat{w}$, which means that MLE is not well-defined in this case. (Hint: You can show this by taking the derivative of L(c$\\hat{w}$) with respect to c, where L is the likelihood function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e2df0",
   "metadata": {},
   "source": [
    "# Problem 4 Prompt:\n",
    "\n",
    "Prove the objective function $J_{logistic}$ is convex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf3042",
   "metadata": {},
   "source": [
    "# Problem 5 Prompt\n",
    "\n",
    "Complete the f objective function in the skeleton code, which computes the objective function for $J_{logistic(w)}$. (Hint: you may get numerical overflow when computing the exponential literally, e.g. try $e^{1000}$ in Numpy. Make sure to read about the log-sum-exp trick and use the numpy function logaddexp to get accurate calculations and to prevent overflow.\n",
    "\n",
    "## Problem 5 answer \n",
    "Done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b17b21fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T18:57:05.402740Z",
     "start_time": "2022-03-21T18:57:05.388486Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f_objective(theta, X, y, l2_param=1):\n",
    "    '''\n",
    "    Args:\n",
    "        theta: 1D numpy array of size num_features\n",
    "        X: 2D numpy array of size (num_instances, num_features)\n",
    "        y: 1D numpy array of size num_instances\n",
    "        l2_param: regularization parameter\n",
    "\n",
    "    Returns:\n",
    "        objective: scalar value of objective function\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    scalar = 1/n\n",
    "    loss = 0\n",
    "    for i in range(n):\n",
    "        \"\"\"\n",
    "        logaddexp adds the log(e^(input1), e^input2)\n",
    "        since we want it to be log(1+e^(-y*theta^Tx)) we need to actually pass\n",
    "        0 in as our first input so e^(0) = 1\n",
    "        \"\"\"\n",
    "        loss+=np.logaddexp(0,-y[i]*np.dot(theta,X[i]))\n",
    "    loss*=scalar\n",
    "    return(loss+l2_param*np.dot(theta,theta))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d1618",
   "metadata": {},
   "source": [
    "# Problem 6 Prompt\n",
    "\n",
    "Complete the fit logistic regression function in the skeleton code using the minimize function from scipy.optimize. Use this function to train a model on the provided data. Make sure to take the appropriate preprocessing steps, such as standardizing the data and adding a column for the bias term.\n",
    "\n",
    "## Problem 6 Answer\n",
    "\n",
    "        function completed in the next cell\n",
    "        data loading and preprocessing completed in the cell after \n",
    "        training the model done in the third cell down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bad44fe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T18:57:06.728318Z",
     "start_time": "2022-03-21T18:57:06.717518Z"
    }
   },
   "outputs": [],
   "source": [
    "### Finishing the function\n",
    "from scipy.optimize import minimize\n",
    "from functools import partial\n",
    "def fit_logistic_reg(X, y, objective_function, l2_param=1):\n",
    "    '''\n",
    "    Args:\n",
    "        X: 2D numpy array of size (num_instances, num_features)\n",
    "        y: 1D numpy array of size num_instances\n",
    "        objective_function: function returning the value of the objective\n",
    "        l2_param: regularization parameter\n",
    "        \n",
    "    Returns:\n",
    "        optimal_theta: 1D numpy array of size num_features\n",
    "    '''\n",
    "    \"\"\"logic\n",
    "            create an initial feature vector of 1's\n",
    "            create a partial objective function using functools.partial that passes in our \n",
    "            X data, Y data and l2 parameter\n",
    "            call scipy.optimize.minimize on the objective function passing in our initial\n",
    "            feature vector\n",
    "            return the optimized weights\n",
    "    \"\"\"\n",
    "\n",
    "    num_feats = X.shape[1]\n",
    "    w_initial = np.ones(num_feats)\n",
    "    obj_func = partial(objective_function, X=X, y=y, l2_param=l2_param)\n",
    "    \"\"\"\n",
    "    minimize function takes in the function to minimize, with an initial weight vector guess\n",
    "    the optimal feature values are obtained with the .x attribute\n",
    "    \"\"\"\n",
    "    w_star = minimize(obj_func,w_initial).x\n",
    "    return(w_star)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "98067ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T18:57:11.201299Z",
     "start_time": "2022-03-21T18:57:11.136490Z"
    }
   },
   "outputs": [],
   "source": [
    "### loading and cleaning data\n",
    "path = 'logistic-code/'\n",
    "file_names = ['X_train.txt', 'X_val.txt', 'y_train.txt', 'y_val.txt']\n",
    "path_list = [path + file_name for file_name in file_names]\n",
    "\n",
    "for i in range(len(path_list)):\n",
    "    if i == 0:\n",
    "        with open(path_list[i]) as textFile:\n",
    "            x_train = [line.split() for line in textFile]\n",
    "        #change data type to reflect an array as data are comma seperated\n",
    "        x_train = [[float(value) for value in row[0].split(',')] for row in x_train]\n",
    "    elif i == 1:\n",
    "        with open(path_list[i]) as textFile:\n",
    "            x_val = [line.split() for line in textFile]\n",
    "        x_val = [[float(value) for value in row[0].split(',')] for row in x_val]\n",
    "    elif i == 2:\n",
    "        with open(path_list[i]) as textFile:\n",
    "                y_train = [line.split() for line in textFile]\n",
    "        y_train = [[float(value) for value in row[0].split(',')] for row in y_train]\n",
    "    else:\n",
    "        with open(path_list[i]) as textFile:\n",
    "            y_val = [line.split() for line in textFile]\n",
    "        y_val = [[float(value) for value in row[0].split(',')] for row in y_val]\n",
    "\n",
    "            \n",
    "        \n",
    "#convert data into numpy arrays\n",
    "x_train, x_val, y_train, y_val,   = np.array(x_train), np.array(x_val), np.array(y_train), np.array(y_val)\n",
    "\n",
    "#preprocessing the data: standardizing the input data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SS = partial(StandardScaler().fit_transform)\n",
    "\n",
    "x_train, x_val = SS(x_train), SS(x_val)\n",
    "\n",
    "##preprocessing the data: adding a bias column to x_train and x_val using np.hstack()\n",
    "x_train = np.hstack((x_train, np.ones((x_train.shape[0],1))))\n",
    "x_val = np.hstack((x_val, np.ones((x_val.shape[0],1))))\n",
    "\n",
    "##change y train and val labels to -1 from 0\n",
    "y_train[y_train == 0 ] = -1\n",
    "y_val[y_val==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7de86fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T18:57:14.360152Z",
     "start_time": "2022-03-21T18:57:11.286987Z"
    }
   },
   "outputs": [],
   "source": [
    "theta = fit_logistic_reg(x_train, y_train, f_objective, l2_param =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4bb6b",
   "metadata": {},
   "source": [
    "# Problem 7 Prompt\n",
    "\n",
    "Find the L2 regularization parameter that minimizes the log-likelihood on the validation set. Plot the log-likelihood for different values of the regularization parameter.\n",
    "\n",
    "## Problem 7 Answer\n",
    "done below \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "aeef45bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T19:08:12.796147Z",
     "start_time": "2022-03-21T19:07:32.300698Z"
    }
   },
   "outputs": [],
   "source": [
    "def negative_log_likelihood(theta,X,y):\n",
    "    n = X.shape[0]\n",
    "    loss = 0\n",
    "    for i in range(n):\n",
    "        loss +=np.logaddexp(0,-y[i]*np.dot(theta,X[i]))\n",
    "    return(-loss)\n",
    "\n",
    "##initially started with a linspace between 0 and 2 \n",
    "#and noticed decreasing validation performance, so did a narrower range between 0-.1\n",
    "\n",
    "#lambda_list = np.linspace(0,2,10)\n",
    "lambda_list = np.arange(0,.1,.01)\n",
    "\n",
    "\n",
    "result_dict = dict()\n",
    "for lam in lambda_list:\n",
    "    theta = fit_logistic_reg(x_train, y_train,f_objective, l2_param=lam)\n",
    "    result_dict[lam] = negative_log_likelihood(theta,x_val,y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "38c62200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T19:08:12.873846Z",
     "start_time": "2022-03-21T19:08:12.812650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_axis = list(result_dict.keys())\n",
    "y_values = list(result_dict.values())\n",
    "plt.plot(x_axis,y_values)\n",
    "plt.xlabel('lambda value')\n",
    "plt.ylabel('negative log likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6cea806d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T19:25:26.793130Z",
     "start_time": "2022-03-21T19:25:26.778931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(result_dict, key=result_dict.get)\n",
    "#optimal lambda = .02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d9197",
   "metadata": {},
   "source": [
    "# Problem 8 Prompt\n",
    "\n",
    "Plot the calibration of your model's probabilistic output. Calibration refers to the proportion of Y = 0 events occur for a given model score (i.e. if the score is .3, we would expect 30% of events to have a label of 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd55921",
   "metadata": {},
   "source": [
    "# Problem 9\n",
    "\n",
    "Consider flipping a biased coin where p (z= H| $\\theta_{1}$) =  $\\theta_{1}$. However, we can't observe the flip directly, and have it reported to us. There is a probability the report is incorrect **if the outcome is a head**, denoted by x: p(x = H|z=H,$\\theta_{2}$) = $\\theta_{2}$. If the outcome is a tails, it will always be correctly reported.\n",
    "\n",
    "**Show that P(x=h|$\\theta_{1}$.$\\theta_{2}$) = $\\theta_{1}$$\\theta_{2}$**\n",
    "\n",
    "The probability of the report being heads, given the probability of the coin is heads ($\\theta_{1}$) and the probability of the report being accurate is ( $\\theta_{2}$)\n",
    "\n",
    "## Problem 9 answer\n",
    "\n",
    "We know that if the report was heads, the outcome of the coin flip **must have been a heads**, which has a probability of $\\theta_{1}$.\n",
    "\n",
    "Given an outcome of the event was heads, the report will take value of heads with probability of $\\theta_{2}$\n",
    "\n",
    "Therefore the probability of observing a reported heads, would be the probability of the coin flipping heads, multiplied by the probability that the report is heads given a heads outcome:\n",
    "\n",
    "$\\theta_{1}$ * $\\theta_{2}$\n",
    "\n",
    "## Q.E.D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e0fa3c",
   "metadata": {},
   "source": [
    "# Problem 10 Prompt\n",
    "Given a set of reported results $D_{r}$ of size N, where r = the number of reported heads = h and the number of reported tails = t, what is the likelihood of $D_{r}$ as a function of $\\theta_{1}$ and $\\theta_{2}$\n",
    "\n",
    "## Problem 10 Answer\n",
    "\n",
    "$$L(D_{r}) = P(x=H | \\theta_{1}, \\theta_{2})^{r}*P(x=T|\\theta_{1}, \\theta_{2})^{t} $$\n",
    "\n",
    "$$P(x=H | \\theta_{1}, \\theta_{2})^{r} = (\\theta_{1}\\theta_{2})^{r}$$\n",
    "$$P(x=T | \\theta_{1}, \\theta_{2})^{r} = (1-\\theta_{1})^{t}(1-\\theta_{2})^{r}$$\n",
    "\n",
    "Therefore \n",
    "$$L(D_{r}) =(\\theta_{1}\\theta_{2})^{r}(1-\\theta_{1})^{t}(1-\\theta_{2})^{r}$ $$\n",
    "\n",
    "### Q.E.D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c36bf",
   "metadata": {},
   "source": [
    "# Problem 11 Prompt\n",
    "Can we estimate $\\theta_{1}$ and $\\theta_{2}$ using MLE, explain your judgment\n",
    "\n",
    "## Problem 11 answer\n",
    "\n",
    "We cannot adequately estimate these two parameters with MLE, as cannot understand the relati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef78d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
