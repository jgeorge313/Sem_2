{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43DBqagWutAE"
   },
   "source": [
    "# Responsible Data Science Spring 2022: Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtYGFyqSm2nk",
    "outputId": "ba8467da-c5e2-459f-8bd8-6f7d6c2de88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'superquail'...\n",
      "remote: Enumerating objects: 24, done.\u001b[K\n",
      "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
      "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
      "remote: Total 24 (delta 1), reused 20 (delta 1), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (24/24), done.\n",
      "Collecting aif360==0.3.0\n",
      "  Downloading aif360-0.3.0-py3-none-any.whl (165 kB)\n",
      "\u001b[K     |████████████████████████████████| 165 kB 4.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (3.2.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (1.3.5)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360==0.3.0) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360==0.3.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360==0.3.0) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->aif360==0.3.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->aif360==0.3.0) (3.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.3.0) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.3.0) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.3.0) (1.3.2)\n",
      "Installing collected packages: aif360\n",
      "Successfully installed aif360-0.3.0\n",
      "Collecting BlackBoxAuditing\n",
      "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.3.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.21.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->BlackBoxAuditing) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n",
      "Building wheels for collected packages: BlackBoxAuditing\n",
      "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394770 sha256=3da263091a6c5c737b93d4be950468e27f86a41c4bd11e281dc789d2daf69d65\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/9f/ee/541a74be4cf5dad17430e64d3276370ea7b6a834a76cb4215a\n",
      "Successfully built BlackBoxAuditing\n",
      "Installing collected packages: BlackBoxAuditing\n",
      "Successfully installed BlackBoxAuditing-0.1.54\n",
      "Collecting tensorflow==1.13.1\n",
      "  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 92.6 MB 1.1 MB/s \n",
      "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
      "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 39.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.44.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
      "\u001b[K     |████████████████████████████████| 367 kB 56.1 MB/s \n",
      "\u001b[?25hCollecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 5.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.11.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0.2)\n",
      "Collecting mock>=2.0.0\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
      "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.8.0\n",
      "    Uninstalling tensorflow-estimator-2.8.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.8.0\n",
      "    Uninstalling tensorflow-2.8.0:\n",
      "      Successfully uninstalled tensorflow-2.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
      "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n",
      "Collecting folktables\n",
      "  Downloading folktables-0.0.11.tar.gz (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from folktables) (1.21.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from folktables) (1.3.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folktables) (2.23.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from folktables) (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->folktables) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->folktables) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->folktables) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (2.10)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->folktables) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (1.1.0)\n",
      "Building wheels for collected packages: folktables\n",
      "  Building wheel for folktables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for folktables: filename=folktables-0.0.11-py3-none-any.whl size=6779 sha256=35fb62f2a1bffe0c565c0272872ed916112a17b4ee754caef12fce650f3ab70f\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/63/b8/24d3f5d2c70002c68c1fe8e78e1de20fcbcb7a2ef3f56147b7\n",
      "Successfully built folktables\n",
      "Installing collected packages: folktables\n",
      "Successfully installed folktables-0.0.11\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/lurosenb/superquail\n",
    "!pip install aif360==0.3.0 \n",
    "!pip install BlackBoxAuditing\n",
    "!pip install tensorflow==1.13.1\n",
    "!pip install folktables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BAY1cNGuxfk",
    "outputId": "d6ed46cc-ff15-43bc-ba10-a3fd39a2bd83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:root:No module named 'numba.decorators': LFR will be unavailable. To install, run:\n",
      "pip install 'aif360[LFR]'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(27)\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, ACSPublicCoverage, ACSTravelTime\n",
    "from superquail.data.acs_helper import ACSData\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, PredefinedSplit, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing, RejectOptionClassification\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "from aif360.explainers import MetricTextExplainer, Explainer\n",
    "\n",
    "import BlackBoxAuditing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW83Vu3KvTQB"
   },
   "source": [
    "# Problem 2\n",
    "### **Load and split data** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpySw57tBKEu"
   },
   "source": [
    "#### Load Folktables dataset and set the protected attribute, drop the other protected attribute race\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UH30OASO5pf3"
   },
   "source": [
    "We have included code to read in the folktables dataset. The Folktables dataset is taken from US Census Data and is built to solve a few simple prediction tasks. The sample we pull is data from 2018 in California. The column names are described in the table below. Note that certain categorical variables have been mapped to integer values, which we will keep as is for the following analyses.\n",
    "\n",
    "For more information on the this dataset, please see the following paper:\n",
    "https://eaamo2021.eaamo.org/accepted/acceptednonarchival/EAMO21_paper_16.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErJSui-veHGd"
   },
   "source": [
    "| Column Name | Feature | Description/Notes |\n",
    "| --- | ----------- | --- |\n",
    "| PINCP | Total person’s income | (Target) 1 if >= $50k, 0 if less |\n",
    "| SEX | Sex | (Sensitive Attribute) Male=1, Female=2 |\n",
    "| RAC1P | Race | Dropped from this analysis to focus on one sensitive attribute |\n",
    "| AGEP | Age | Ranges from 0-99 |\n",
    "| COW | Class of Worker | Ranges 1-9, see paper for description |\n",
    "| SCHL | Education Level | Ranges 1-24, see paper for description |\n",
    "| MAR | Marital Status | Ranges 1-5, see paper for description |\n",
    "| OCCP | Occupation | Codes taken from Public Use Microdata Sample (PUMS) from the US Census, see paper |\n",
    "| POBP | Place of Birth | Codes taken from Public Use Microdata Sample (PUMS) from the US Census, see paper |\n",
    "| RELP | Relationship | Relationship of individual to person who responded to the Census taker. Ranges 0-17, see paper for description |\n",
    "| WKHP | Hours worked per week | Ranges from 0-99, averaged over previous year |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "JKV2cQ_Q3IqF",
    "outputId": "461bdedf-108f-41c6-f113-59f9c609de10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 2018 1-Year person survey for CA...\n",
      "(5000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2da0a0b8-c1f3-43d2-8fe0-ed4fbc0253e4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4252.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5140.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4920.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2da0a0b8-c1f3-43d2-8fe0-ed4fbc0253e4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2da0a0b8-c1f3-43d2-8fe0-ed4fbc0253e4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2da0a0b8-c1f3-43d2-8fe0-ed4fbc0253e4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  PINCP\n",
       "0  53.0  2.0  21.0  3.0  5400.0  233.0  15.0  30.0  1.0    0.0\n",
       "1  51.0  2.0  21.0  1.0   350.0  217.0   0.0  40.0  2.0    1.0\n",
       "2  45.0  6.0  21.0  1.0  4252.0    6.0   0.0  30.0  1.0    0.0\n",
       "3  62.0  1.0  19.0  1.0  5140.0   48.0   0.0  40.0  2.0    0.0\n",
       "4  63.0  6.0  19.0  1.0  4920.0   17.0   0.0  10.0  1.0    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(27)\n",
    "protected_attr = 'SEX' #set sex as the protected attribute\n",
    "target = 'PINCP' #personal income as the target (1=(>50k))\n",
    "\n",
    "#read in the folktables dataset \n",
    "##change sample size back to 70 K later!!\n",
    "full_df, features_df, target_df, groups_df = ACSData().return_acs_data_scenario(scenario=\"ACSIncome\", subsample=50000)\n",
    "full_df = full_df.drop(columns='RAC1P') #drop race -- another protected attribute from our dataset\n",
    "\n",
    "print(full_df.shape)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cEZljEsG4G1j"
   },
   "outputs": [],
   "source": [
    "# convert this dataframe into an aif360 dataset\n",
    "dataset_orig = BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=full_df,\n",
    "    label_names=[target],\n",
    "    protected_attribute_names=[protected_attr])\n",
    "\n",
    "\n",
    "privileged_groups = [{protected_attr: 1}] \n",
    "unprivileged_groups = [{protected_attr: 2}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fa2JenjzLkx"
   },
   "source": [
    "### Create the train test val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCy6GcbgBycv",
    "outputId": "6f0814bb-dc4f-4156-a971-652f1145caca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  (3500, 10)\n",
      "Val set:  (500, 10)\n",
      "Test set:  (1000, 10)\n",
      "Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7334062461251832 \n",
      " Mean difference (mean label value on unprivileged instances - mean label value on privileged instances): -0.12665049526185895\n",
      "In our combined training and validation datasets, women receive a label of 1, 75%  as often as men\n"
     ]
    }
   ],
   "source": [
    "#split data into train_orig, containing 80% and test_orig\n",
    "train_orig, test_orig = dataset_orig.split([0.8], shuffle=True , seed= 27)\n",
    "#create train_new and val_new, train_new has 70% of data, val_new has 10% of data, used for training and validation\n",
    "train_new, val_new = train_orig.split([.875],shuffle=True)\n",
    "\n",
    "\n",
    "# Convert to dataframes\n",
    "train_orig_df, _ = train_orig.convert_to_dataframe()\n",
    "train_new_df,_ =train_new.convert_to_dataframe()\n",
    "val_new_df, _ = val_new.convert_to_dataframe()\n",
    "test_orig_df, _ = test_orig.convert_to_dataframe()\n",
    "\n",
    "\n",
    "#inspect shapes\n",
    "print(\"Train set: \", train_new_df.shape)\n",
    "print(\"Val set: \", val_new_df.shape)\n",
    "print(\"Test set: \", test_orig_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "#examine baseline disparate impact and mean difference\n",
    "metric_orig_panel19_train = BinaryLabelDatasetMetric(\n",
    "        train_orig,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups)\n",
    "explainer_orig_panel19_train = MetricTextExplainer(metric_orig_panel19_train)\n",
    "\n",
    "print(explainer_orig_panel19_train.disparate_impact(),'\\n',explainer_orig_panel19_train.mean_difference())\n",
    "\n",
    "print('In our combined training and validation datasets, women receive a label of 1, 75%  as often as men')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaQZc9mkDBQc"
   },
   "source": [
    "# Problem 2, Part (a) \n",
    "### **Train a baseline Random Forest (RF) model and report metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_9U8nMU3pg0"
   },
   "source": [
    "### Train a random forest model - Baseline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Nldecw7mzya",
    "outputId": "27a81267-b151-4bfe-b2d2-8dbc696ffaa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2332\n",
       "1.0    1668\n",
       "Name: PINCP, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create train and test vectors used for \n",
    "x_train, x_test = train_orig_df.drop(target, axis=1), test_orig_df.drop(target, axis=1)\n",
    "\n",
    "y_train, y_test= train_orig_df.PINCP,  test_orig_df.PINCP\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kIfPM-1kx9f",
    "outputId": "cec6c34c-7ab5-4eb8-ff90-1be050d61393"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', MinMaxScaler(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f692cdc1f10>),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f692cdc1f90>)])),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=1, n_estimators=1))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess data using min max scalar and one hot encode variables\n",
    "unmitigated_predictor = Pipeline(\n",
    "    steps=[\n",
    "           #feature engineering component \n",
    "        (\"preprocessor\", ColumnTransformer(transformers=[\n",
    "                                              # we use selector to indentify features based on its data type\n",
    "                                              # Normalize numerical features\n",
    "                                               (\"num\", MinMaxScaler(), selector(dtype_exclude=\"category\")), \n",
    "                                              # Encoding (transforming) categorical features to what understandable by the model\n",
    "                                              (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), selector(dtype_include=\"category\")),\n",
    "                                            ]\n",
    "                                          )\n",
    "        ),\n",
    "        # model component\n",
    "        (\"classifier\",RandomForestClassifier(max_depth = 1, n_estimators=1),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "#fit predictor object on the training data\n",
    "unmitigated_predictor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pioye8vUP_I5"
   },
   "source": [
    "## Problem 2A:\n",
    "\n",
    "Train a baseline Randomforest, with max_depth = 1 and num_estimators = 1 and report performance on the five metrics of interest on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bo149tbl3n_N"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_orig_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ec699029ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create new dataframe with predictions as the target column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_pred_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_orig_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_pred_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmitigated_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#initiate a metric list to be used when examining metrics of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_orig_df' is not defined"
     ]
    }
   ],
   "source": [
    "#create new dataframe with predictions as the target column\n",
    "test_pred_df = test_orig_df.copy()\n",
    "test_pred_df[target] = unmitigated_predictor.predict(x_test)\n",
    "\n",
    "#initiate a metric list to be used when examining metrics of interest\n",
    "metric_list = ['accuracy','privileged_groups_accuracy', 'unprivileged_groups_accuracy','disparate_impact','false_positive_difference_rate']\n",
    "\n",
    "#create AIF360 objects as input to a ClassificationMetric \n",
    "preds_aif360 = StandardDataset(test_pred_df, label_name=target,\n",
    "                protected_attribute_names=[protected_attr], \n",
    "                privileged_classes=[[1]], favorable_classes=[1])\n",
    "\n",
    "orig_aif360 = StandardDataset(test_orig_df, label_name=target,\n",
    "                protected_attribute_names=[protected_attr], \n",
    "                privileged_classes=[[1]], favorable_classes=[1])\n",
    "\n",
    "#store model performance in Classification metric Object\n",
    "metrics_final = ClassificationMetric(orig_aif360, preds_aif360, \n",
    "                unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ci-ClRL14Efm"
   },
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MAAkD4VK37eg"
   },
   "outputs": [],
   "source": [
    "def calculate_metric(metric_list, ClassificationMetrObj, verbose):\n",
    "    \"\"\"\n",
    "  function used to examine the 5 metrics of interest for ClassificationMetrObjects\n",
    "  \"\"\"\n",
    "      for metric in metric_list:\n",
    "        message = metric +' is '\n",
    "          if metric == 'accuracy':\n",
    "            statement = round(ClassificationMetrObj.accuracy(),5)\n",
    "        elif metric == 'privileged_groups_accuracy':\n",
    "            statement = round(ClassificationMetrObj.accuracy(privileged=True),5)\n",
    "        elif metric == 'unprivileged_groups_accuracy':\n",
    "            statement = round(ClassificationMetrObj.accuracy(privileged=False),5)\n",
    "        elif metric == 'disparate_impact':\n",
    "            statement = round(ClassificationMetrObj.disparate_impact(),5)\n",
    "        else:\n",
    "            statement = round(ClassificationMetrObj.false_positive_rate_difference(),5)\n",
    "        if verbose == True:\n",
    "            print(message + str(statement)) \n",
    "        return(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSvJNZNc22AC",
    "outputId": "aee27760-25c2-4342-f426-6b13d57b3eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.605\n",
      "privileged_groups_accuracy is 0.61731\n",
      "unprivileged_groups_accuracy is 0.59167\n",
      "disparate_impact is 0.84866\n",
      "false_positive_difference_rate is -0.09328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.09328"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print statements to show model performance\n",
    "calculate_metric(metric_list[0:],metrics_final, True)\n",
    "calculate_metric(metric_list[1:],metrics_final, True)\n",
    "calculate_metric(metric_list[2:],metrics_final, True)\n",
    "calculate_metric(metric_list[3:],metrics_final, True)\n",
    "calculate_metric(metric_list[4:],metrics_final, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qZgybMrFsKB"
   },
   "source": [
    "# Problem 2, Part (b)\n",
    "### **Hyperparameter tuning of baseline RF model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yokMPYTHKB7A"
   },
   "source": [
    "### Define a program to conduct tune the Random Forest\n",
    "Optimize the Accuracy. You should try the following hyperparameters: <br>\n",
    "max_depth=[1, 5, 10] <br>\n",
    "n_estimators=[1, 5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7TpjRCHpClL4"
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "def tune_base_rf():\n",
    "    \"\"\"\n",
    "  function that sequentially:\n",
    "      creates a train/val/test datasplit  \n",
    "      specifies a hyperparameters grid to iterate over using RandomSearchCV\n",
    "      fits a model to each training dataset using a base model,\n",
    "      validates optimal hyperparameters on the validation dataset\n",
    "      captures test set performance for both models\n",
    "      stores the results to a dictionary\n",
    "      repeats this process 9 more times times\n",
    "      outputs the dictionary of results\n",
    "  \"\"\"\n",
    "\n",
    "  #initialize seed values used in data splitting\n",
    "    seed_list = [27,100,65,12345,59,210398,4231,45,1,98753]\n",
    "\n",
    "  #create gridSearchCV inputs\n",
    "    max_depth_list = [1,5,10]\n",
    "    n_estimators_list = [1,5,10,15,20]\n",
    "    param_grid = [{'classifier__max_depth':max_depth_list,\n",
    "                 'classifier__n_estimators':n_estimators_list\n",
    "                 }]\n",
    "  #dictionary that will be our final output\n",
    "    run_dict = {}\n",
    "    for i in range(len(seed_list)):\n",
    "\n",
    "    #create an index for each run in our dictionary,\n",
    "    #that corresponds to a nested dictionary\n",
    "    run_dict[i] = {}\n",
    "\n",
    "\n",
    "    #create splits for train,validation and test datasets\n",
    "    train_orig, test_orig = dataset_orig.split([0.8], shuffle=True , seed= seed_list[i])\n",
    "    train_new, val_new = train_orig.split([.875],shuffle=True, seed = seed_list[i])\n",
    "   \n",
    "    #create dataframe objects \n",
    "    train_orig_df, _ = train_orig.convert_to_dataframe()\n",
    "    train_new_df,_ =train_new.convert_to_dataframe()\n",
    "    val_new_df, _ = val_new.convert_to_dataframe()\n",
    "    test_orig_df, _ = test_orig.convert_to_dataframe()\n",
    "\n",
    "    #create vectors for base and tuned models\n",
    "\n",
    "    x_base_train, x_base_test = train_orig_df.drop(target, axis=1), test_orig_df.drop(target, axis=1)\n",
    "    y_base_train, y_base_test= train_orig_df.PINCP,  test_orig_df.PINCP\n",
    "\n",
    "\n",
    "    x_val_train, x_val_test = train_new_df.drop(target, axis=1), val_new_df.drop(target, axis=1)\n",
    "    y_val_train, y_val_test = train_new_df.PINCP, val_new_df.PINCP\n",
    "\n",
    "    #create splits for hyperparameter tuning\n",
    "    split_index = [-1 if x in x_val_train.index else 0 for x in x_base_train.index]\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "\n",
    "\n",
    "    #create pipeline object\n",
    "    unmitigated_predictor = Pipeline(\n",
    "        steps=[\n",
    "              #feature engineering component \n",
    "            (\"preprocessor\", ColumnTransformer(transformers=[\n",
    "                                                  # we use selector to indentify features based on its data type\n",
    "                                                  # Normalize numerical features\n",
    "                                                  (\"num\", MinMaxScaler(), selector(dtype_exclude=\"category\")), \n",
    "                                                  # Encoding (transforming) categorical features to what understandable by the model\n",
    "                                                  (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), selector(dtype_include=\"category\")),\n",
    "                                                ]\n",
    "                                              )\n",
    "            ),\n",
    "            # model component\n",
    "            (\"classifier\",RandomForestClassifier(max_depth = 1, n_estimators=1),\n",
    "            ),\n",
    "        ])\n",
    "    \n",
    "    #fit our base model on the training data, without using validation dataset\n",
    "    \n",
    "    unmitigated_predictor.fit(x_base_train, y_base_train)\n",
    "\n",
    "\n",
    "\n",
    "    #create RandomizedSearhCV finding the optimized weights for this split on our validaiton data,\n",
    "    clf = RandomizedSearchCV(unmitigated_predictor,\n",
    "                         n_iter=10,\n",
    "                         cv = pds,\n",
    "                         scoring = 'accuracy',\n",
    "                         param_distributions = param_grid)\n",
    "    \n",
    "    #fit the model with various hyperparameters on the training and validation dataset\n",
    "    clf.fit(x_base_train,y_base_train)\n",
    "\n",
    "    #capture the best accuracy and parameters of our tuned model\n",
    "    run_dict[i]['max_validation_score'] = clf.best_score_\n",
    "    run_dict[i]['params'] =clf.best_params_\n",
    "\n",
    "\n",
    "\n",
    "    ##create dataframe objects that will be \n",
    "    base_pred_df = test_orig_df.copy()\n",
    "    base_pred_df[target] = unmitigated_predictor.predict(x_base_test)\n",
    "    tuned_pred_df = test_orig_df.copy()\n",
    "    tuned_pred_df[target] = clf.predict(x_base_test)\n",
    "\n",
    "\n",
    "    ##create AIF360 datasets \n",
    "    base_aif360 = StandardDataset(base_pred_df, label_name=target, protected_attribute_names=[protected_attr], \n",
    "                privileged_classes=[[1]], favorable_classes=[1])\n",
    "    preds_aif360 = StandardDataset(tuned_pred_df, label_name=target, protected_attribute_names=[protected_attr], \n",
    "                privileged_classes=[[1]], favorable_classes=[1])\n",
    "    orig_aif360 = StandardDataset(test_orig_df, label_name=target, protected_attribute_names=[protected_attr], \n",
    "                privileged_classes=[[1]], favorable_classes=[1])\n",
    "\n",
    "    #create the classification metric object to store\n",
    "    metrics_tuned = ClassificationMetric(orig_aif360, preds_aif360, unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups)\n",
    "    metrics_base = ClassificationMetric(orig_aif360, base_aif360, unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups)\n",
    "   \n",
    "    #store the classificatoin metric objects in our dictionary\n",
    "    run_dict[i]['base_metric'] = metrics_base\n",
    "    run_dict[i]['tuned_metric'] = metrics_tuned\n",
    "    return(run_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmW4nlgDOUKS"
   },
   "source": [
    "### Compare the initial model to the fine-tuned model for 10 train/val/test splits for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TbGfeNNmOMft"
   },
   "outputs": [],
   "source": [
    "def compute_metric_lists(dict, metric_list, repair):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    dict -- a dictionary containing ClassificationMetric Objects that we will use to evaluate model metrics of interest\n",
    "    metric_list -- a list of the metrics we want to evaluate \n",
    "    repair -- a boolean that indicates if the metrics we are interested in are a result of the repairing process, \n",
    "    which has a different input structure than the other problems\n",
    "\n",
    "  returns: a dictionary of the metrics of interest for problems 2b-2e\n",
    "\n",
    "  \"\"\"\n",
    "    if repair == False:\n",
    "    initial_metric_dict, tuned_metric_dict = {}, {}\n",
    "    for metric in metric_list:\n",
    "        initial_metric_dict[metric] = []\n",
    "        tuned_metric_dict[metric] = []\n",
    "\n",
    "    \"\"\"\n",
    "    used for the tuning vs non tuning metric evaluation (2b/2)\n",
    "\n",
    "    \"\"\"\n",
    "    for k,v in dict.items():\n",
    "        if 'base_metric' in v.keys():\n",
    "            for metric in metric_list:\n",
    "                initial_metric_dict[metric].append(calculate_metric([metric],v['base_metric'],verbose=False))\n",
    "                tuned_metric_dict[metric].append(calculate_metric([metric],v['tuned_metric'],verbose=False))\n",
    "        else:\n",
    "\n",
    "             \"\"\"\n",
    "             used for the ROC metric evaluation (2e)\n",
    "\n",
    "             \"\"\"\n",
    "            for metric in metric_list:\n",
    "                tuned_metric_dict[metric].append(calculate_metric([metric],v['metric_list'],verbose=False))\n",
    "            if initial_metric_dict:\n",
    "                return(initial_metric_dict,tuned_metric_dict)\n",
    "            else:\n",
    "                return(tuned_metric_dict)\n",
    "\n",
    "        \"\"\"\n",
    "        used for the Repair prediction metric evaluation (2c/2d)\n",
    "\n",
    "        \"\"\"\n",
    "    elif repair== True:\n",
    "        repair_metric_dict = {}\n",
    "        for metric in metric_list:\n",
    "            repair_metric_dict[metric] = []\n",
    "        for i in range(len(dict)):\n",
    "            for metric in metric_list:\n",
    "                repair_metric_dict[metric].append(calculate_metric([metric],\n",
    "                                          dict[i],verbose=False))\n",
    "\n",
    "        return(repair_metric_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tPthXRZyd4Ok"
   },
   "outputs": [],
   "source": [
    "output_dict = tune_base_rf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Q7dUnodxd4qf"
   },
   "outputs": [],
   "source": [
    "initial_metrics, tuned_metrics = compute_metric_lists(output_dict, metric_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA0k80PlefxC"
   },
   "outputs": [],
   "source": [
    "# for boxplots\n",
    "def plot_init_v_tuned_box(init_metrics, tuned_metrics, metric_name):\n",
    "  \n",
    "    '''Creates a bar graph comparing init_metrics to tuned_metrics'''\n",
    "\n",
    "  # Make some x values\n",
    "    x_init = list(range(len(init_metrics)))\n",
    "    x_tuned = [x + 0.35 for x in x_init]\n",
    "    # Plot the metrics\n",
    "    plt.boxplot([init_metrics, tuned_metrics], labels=['Initial Model', 'Tuned Model'])\n",
    "    plt.title('comparing untuned and tuned Random Forest ' + metric_name)\n",
    "    # Create labels, etc. \n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "xNJEKL7VegsW",
    "outputId": "e2f3479c-5ba4-4c4d-f8aa-468482c3da7b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create 5 graphs \n",
    "fig, axs = plt.subplots(1,5, figsize=(30,10))\n",
    "\n",
    "for i in range(len(metric_list)):\n",
    "    metric = metric_list[i]\n",
    "    ax = axs[i] \n",
    "    pcm = ax.boxplot([initial_metrics[metric], tuned_metrics[metric]], labels = ['Initial Model', 'Tuned Model'])\n",
    "    ax.title.set_text('Comparing performance on ' + metric)\n",
    "    ax.set_ylabel(metric)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKhDj-XJRUJL"
   },
   "source": [
    "# Problem 2, Part (c) \n",
    "### **Disparate Impact Pre-Processing intervention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OWmm6T0VmIz"
   },
   "outputs": [],
   "source": [
    "#tuned_metrics \n",
    "#uncomment the above to analyze which parameters did the best out of our 5 metrics of interest\n",
    "\n",
    "#best performance on test set data was run 4, which had parameters of max_depth = 10 and n_estimators = 20\n",
    "output_dict[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OdKAmnvdxXk"
   },
   "outputs": [],
   "source": [
    "#create 10 data points to plot performance over repair level\n",
    "repair_list = np.linspace(0,1,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTDCigomd3V7"
   },
   "outputs": [],
   "source": [
    "def repair_tuned_rf(repair_list):\n",
    "  #initialize seed values used in data splitting\n",
    "    ClassificationMetric_list = []\n",
    "    seed_list = [27,100,65,12345,59,210398,4231,45,1,98753]\n",
    "    for i in range(len(repair_list)):\n",
    "        repair = DisparateImpactRemover(repair_list[i],sensitive_attribute='SEX')\n",
    "        train_orig, test_orig = dataset_orig.split([0.8], shuffle=True , seed= seed_list[i])\n",
    "\n",
    "\n",
    "  #apply preprocessing to our data\n",
    "        repair_train = repair.fit_transform(train_orig)\n",
    "        repair_test = repair.fit_transform(test_orig)\n",
    "  \n",
    "  #create dataframe objects \n",
    "        repair_train_orig_df, _ = repair_train.convert_to_dataframe()\n",
    "        repair_test_orig_df, _ = repair_test.convert_to_dataframe()\n",
    "\n",
    "  #create vectors for base and tuned models\n",
    "\n",
    "        x_base_train =  repair_train_orig_df.drop(target, axis=1)\n",
    "        x_base_test  = repair_test_orig_df.drop(target, axis=1)\n",
    "        y_base_train = repair_train_orig_df.PINCP\n",
    "        y_base_test  = repair_test_orig_df.PINCP\n",
    "\n",
    "\n",
    "        #replicate our best predictor\n",
    "        tuned_predictor = Pipeline(\n",
    "              steps=[\n",
    "                    #feature engineering component \n",
    "                  (\"preprocessor\", ColumnTransformer(transformers=[\n",
    "                                                        # we use selector to indentify features based on its data type\n",
    "                                                        # Normalize numerical features\n",
    "                                                        (\"num\", MinMaxScaler(), selector(dtype_exclude=\"category\")), \n",
    "                                                        # Encoding (transforming) categorical features to what understandable by the model\n",
    "                                                        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), selector(dtype_include=\"category\")),\n",
    "                                                      ]\n",
    "                                                    )\n",
    "                  ),\n",
    "                  # model component\n",
    "                  #using optimal hyperparameters after RandomSearch CV, determined above\n",
    "                  (\"classifier\",RandomForestClassifier(max_depth = 10, n_estimators=20),\n",
    "                  ),\n",
    "              ])\n",
    "\n",
    "        #fit tuned model\n",
    "        tuned_predictor.fit(x_base_train, y_base_train)\n",
    "\n",
    "        #predict tuned model onto dataframe\n",
    "\n",
    "        tuned_pred_df = test_orig_df.copy()\n",
    "        tuned_pred_df[target] = tuned_predictor.predict(x_base_test)\n",
    "\n",
    "        #create AIF360 objects\n",
    "        preds_aif360 = StandardDataset(tuned_pred_df, label_name=target, protected_attribute_names=[protected_attr], \n",
    "                    privileged_classes=[[1]], favorable_classes=[1])\n",
    "        orig_aif360 = StandardDataset(test_orig_df, label_name=target, protected_attribute_names=[protected_attr], \n",
    "                    privileged_classes=[[1]], favorable_classes=[1])\n",
    "\n",
    "        #store results\n",
    "        ClassificationMetric_list.append(ClassificationMetric(orig_aif360, preds_aif360, unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups))\n",
    "\n",
    "    return(ClassificationMetric_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28k7xUu005-l"
   },
   "outputs": [],
   "source": [
    "#run the func\n",
    "repair_metric_list = repair_tuned_rf(repair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBiW-_DD1w73"
   },
   "outputs": [],
   "source": [
    "#compute 5 metrics of interest\n",
    "repair_metrics = compute_metric_lists(repair_metric_list,metric_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tCQlmH422F7"
   },
   "outputs": [],
   "source": [
    "#create a new key for the repair level itself\n",
    "repair_metrics['repair_level'] = repair_list\n",
    "#repair_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NToBvrQiWIz"
   },
   "outputs": [],
   "source": [
    "def plot_repair_levels(repair_levels, metric_vals, metric_name, x_label='Repair level'):\n",
    "  '''Creates a line plot showing how the metric changed for different values of repair level'''\n",
    "\n",
    "  # Plot the metrics\n",
    "    plt.plot(repair_levels, metric_vals, color='#0384fc', linewidth=3, label=metric_name)\n",
    "\n",
    "    # Create labels, etc. \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PD4QoWNs3cPw"
   },
   "outputs": [],
   "source": [
    "#plot metrics according to repair level\n",
    "fig, axs = plt.subplots(1,5, figsize=(20,10))\n",
    "\n",
    "for i in range(len(metric_list)):\n",
    "    metric = metric_list[i]\n",
    "    ax = axs[i] \n",
    "    pcm = ax.plot(repair_list, repair_metrics[metric], color='#0384fc', linewidth=3, label=metric)\n",
    "    ax.title.set_text('Repair level vs ' + metric)\n",
    "    ax.set_ylabel(metric)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOzr7aximZVH"
   },
   "source": [
    "### Apply pre-processing techniques to the dataset, then re-train the models with the optimal hyperparameters from part **b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9Hu35jTgc3J"
   },
   "outputs": [],
   "source": [
    "def prejudice_remover(eta_list):\n",
    "\n",
    "  #initialize seed values used in data splitting\n",
    "\n",
    "    ClassificationMetric_list = []\n",
    "    seed_list = [27,100,65,12345,59,210398,4231,45,1,98753][0:9]\n",
    "\n",
    "  #for 9 iterations,\n",
    "\n",
    "    for i in range(len(eta_list)):\n",
    "\n",
    "        #split data into train/test\n",
    "        train_orig, test_orig = dataset_orig.split([0.8], shuffle=True , seed= seed_list[i])\n",
    "\n",
    "        #create PrejudiceRemover Object with value of eta\n",
    "        PrejudiceRemoverObj = PrejudiceRemover(eta_list[i])  \n",
    "\n",
    "\n",
    "        #create dataframe objects \n",
    "        train_orig_df, _ = train_orig.convert_to_dataframe()\n",
    "        test_orig_df, _ = test_orig.convert_to_dataframe()\n",
    "\n",
    "        #create a preprocess object\n",
    "        preprocessing = ColumnTransformer(\n",
    "        [(\"scaler\", MinMaxScaler(), [0, 1])],\n",
    "        remainder=\"passthrough\")\n",
    "\n",
    "        #create binarylabeldataset objects for train/test\n",
    "\n",
    "        BinaryTrainDataset = BinaryLabelDataset(favorable_label=1,\n",
    "          unfavorable_label=0,\n",
    "          df=train_orig_df,\n",
    "          label_names=[target],\n",
    "          protected_attribute_names=[protected_attr])\n",
    "\n",
    "        BinaryTestDataSet = BinaryLabelDataset(favorable_label=1,\n",
    "          unfavorable_label=0,\n",
    "          df=test_orig_df,\n",
    "          label_names=[target],\n",
    "          protected_attribute_names=[protected_attr])\n",
    "\n",
    "\n",
    "        #preprocess train/test datasets\n",
    "        BinaryTrainDataset.features = preprocessing.fit_transform(BinaryTrainDataset.features)\n",
    "        BinaryTestDataSet.features = preprocessing.transform(BinaryTestDataSet.features)\n",
    "\n",
    "        #fit the data onto the training data\n",
    "\n",
    "        fit = PrejudiceRemoverObj.fit(BinaryTrainDataset)\n",
    "\n",
    "        #store predictions into a dataframe\n",
    "        unprejudiced_df = test_orig_df.copy()\n",
    "        unprejudiced_df[target] = fit.predict(BinaryTestDataSet).labels\n",
    "\n",
    "        #create aif360 objects\n",
    "        preds_aif360 = StandardDataset(unprejudiced_df, label_name=target, protected_attribute_names=[protected_attr], \n",
    "                    privileged_classes=[[1]], favorable_classes=[1])\n",
    "        orig_aif360 = StandardDataset(test_orig_df, label_name=target, protected_attribute_names=[protected_attr], \n",
    "                    privileged_classes=[[1]], favorable_classes=[1])\n",
    "\n",
    "        #store metrics\n",
    "        ClassificationMetric_list.append(ClassificationMetric(orig_aif360, preds_aif360, unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups))\n",
    "\n",
    "    return(ClassificationMetric_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gu1xtZ6ExCdU"
   },
   "source": [
    "# Problem 2, Part (d) \n",
    "### **Prejudice Remover In-Processing intervention**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3oBrlsSncYr"
   },
   "source": [
    "### Fit new models using the Prejudice Remover technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiejOOrrfEiG"
   },
   "outputs": [],
   "source": [
    "#create eta list to remove prejudice, run func\n",
    "eta_list = np.linspace(0,1,9)\n",
    "\n",
    "unprejudiced_models = prejudice_remover(eta_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObfzKq1bcD-C"
   },
   "outputs": [],
   "source": [
    "#compute metrics\n",
    "unprejudiced_metrics = compute_metric_lists(unprejudiced_models, metric_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4L0PgiaaTSr"
   },
   "outputs": [],
   "source": [
    "#plot performance across eta levels\n",
    "fig, axs = plt.subplots(1,5, figsize=(20,10))\n",
    "\n",
    "for i in range(len(metric_list)):\n",
    "    metric = metric_list[i]\n",
    "    ax = axs[i] \n",
    "    pcm = ax.plot(eta_list, unprejudiced_metrics[metric], color='#0384fc', linewidth=3, label=metric)\n",
    "    ax.title.set_text('Eta level vs ' + metric)\n",
    "    ax.set_ylabel(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6Mgr2iiLb_k"
   },
   "source": [
    "# Problem 2, Part (e) \n",
    "### **Reject Option Post-Processing intervention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvbKbKM1nuLY"
   },
   "source": [
    "### Using the same random forest models as before, apply the post-processing technique to your results and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RK6qmQ_-3MTD"
   },
   "outputs": [],
   "source": [
    "def ROC_rf():\n",
    "  ###steps:\n",
    "      ##split data into train/val/test\n",
    "      #train data using optimally tuned random forest\n",
    "      #pass trained model into ROC classifer, validating on validation dataset\n",
    "      #test new model after post-processing on test dataset\n",
    "\n",
    "  #initialize seed values used in data splitting\n",
    " \n",
    "    seed_list = [27,100,65,12345,59,210398,4231,45,1,98753]\n",
    "\n",
    "  #create gridSearchCV inputs\n",
    "  \n",
    "    final_dict = {}\n",
    "    for i in range(len(seed_list)):\n",
    "        final_dict[i] = {}\n",
    "        #create splits for train,validation and test datasets\n",
    "        train_orig, test_orig = dataset_orig.split([0.8], shuffle=True , seed= seed_list[i])\n",
    "        train_new, val_new = train_orig.split([.875],shuffle=True, seed = seed_list[i])\n",
    "\n",
    "        #create dataframe objects \n",
    "        train_orig_df, _ = train_orig.convert_to_dataframe()\n",
    "        train_new_df,_ =train_new.convert_to_dataframe()\n",
    "        val_new_df, _ = val_new.convert_to_dataframe()\n",
    "        test_orig_df, _ = test_orig.convert_to_dataframe()\n",
    "\n",
    "        #create vectors for base and tuned models\n",
    "\n",
    "        x_base_train, x_base_test = train_orig_df.drop(target, axis=1), test_orig_df.drop(target, axis=1)\n",
    "        y_base_train, y_base_test= train_orig_df.PINCP,  test_orig_df.PINCP\n",
    "\n",
    "\n",
    "        x_val_train, x_val_test = train_new_df.drop(target, axis=1), val_new_df.drop(target, axis=1)\n",
    "        y_val_train, y_val_test = train_new_df.PINCP, val_new_df.PINCP\n",
    "\n",
    "        #create splits for hyperparameter tuning\n",
    "        split_index = [-1 if x in x_val_train.index else 0 for x in x_base_train.index]\n",
    "        pds = PredefinedSplit(test_fold = split_index)\n",
    "        params_list= []\n",
    "\n",
    "        for k in sorted(output_dict[i]['params'].keys()):\n",
    "            params_list.append(output_dict[i]['params'][k])\n",
    "\n",
    "\n",
    "    #create pipeline object\n",
    "        tuned_predictor = Pipeline(\n",
    "            steps=[\n",
    "                  #feature engineering component \n",
    "                (\"preprocessor\", ColumnTransformer(transformers=[\n",
    "                                                      # we use selector to indentify features based on its data type\n",
    "                                                      # Normalize numerical features\n",
    "                                                      (\"num\", MinMaxScaler(), selector(dtype_exclude=\"category\")), \n",
    "                                                      # Encoding (transforming) categorical features to what understandable by the model\n",
    "                                                      (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), selector(dtype_include=\"category\")),\n",
    "                                                    ]\n",
    "                                                  )\n",
    "                ),\n",
    "                # model component\n",
    "                (\"classifier\",RandomForestClassifier(max_depth = params_list[0], n_estimators=params_list[1]),\n",
    "                ),\n",
    "            ])\n",
    "\n",
    "        #fit optimized rf on training data\n",
    "        tuned_predictor.fit(x_base_train, y_base_train)\n",
    "        pos_ind = np.where(tuned_predictor.classes_ == train_orig.favorable_label)[0][0]\n",
    "\n",
    "        #predict on validation data\n",
    "        valid_pred_BLD = val_new.copy()\n",
    "\n",
    "\n",
    "        valid_pred_BLD.scores = tuned_predictor.predict_proba(x_val_test)[:,pos_ind].reshape(-1,1)\n",
    "        fav_inds = valid_pred_BLD.scores > .5\n",
    "\n",
    "        valid_pred_BLD.labels[fav_inds], valid_pred_BLD.labels[~fav_inds] = val_new.favorable_label, val_new.unfavorable_label\n",
    "\n",
    "\n",
    "        #validate optimal ROC parameters on validation dataset\n",
    "        ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups,\n",
    "                                         low_class_thresh = 0.01,\n",
    "                                         high_class_thresh =.99,\n",
    "                                         num_class_thresh = 10,\n",
    "                                         num_ROC_margin=10\n",
    "                                         )\n",
    "\n",
    "        ROC.fit(val_new,valid_pred_BLD)\n",
    "\n",
    "        #store decision boundaries and ROC margin\n",
    "        best_class_threshold = ROC.classification_threshold \n",
    "        best_margin = ROC.ROC_margin\n",
    "\n",
    "        final_dict[i]['class_threshold'] = best_class_threshold\n",
    "        final_dict[i]['margin'] = best_margin\n",
    "\n",
    "        #predict on test datasets\n",
    "\n",
    "        dataset_orig_test_pred = test_orig.copy()\n",
    "        dataset_orig_test_pred.scores = tuned_predictor.predict_proba(x_base_test)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "        #transfrom scores into labels using calcualted decision boundary\n",
    "        fav_inds = dataset_orig_test_pred.scores > best_class_threshold\n",
    "        dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
    "        dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label\n",
    "\n",
    "        #predict data on test set\n",
    "        ROC_Test = ROC.predict(dataset_orig_test_pred)\n",
    "\n",
    "        orig_aif360 = StandardDataset(test_orig_df, label_name=target, protected_attribute_names=[protected_attr], \n",
    "                    privileged_classes=[[1]], favorable_classes=[1])\n",
    "\n",
    "        #store results\n",
    "        final_dict[i]['metric_list']=ClassificationMetric(test_orig, ROC_Test, unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups)\n",
    "    return(final_dict)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUrWBL0_rhup"
   },
   "outputs": [],
   "source": [
    "ROC_list = ROC_rf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbUVsyOxroqD"
   },
   "outputs": [],
   "source": [
    "ROC_metric_list = ['accuracy', 'privileged_groups_accuracy', 'unprivileged_groups_accuracy', 'disparate_impact', 'false_positive_difference_rate',\n",
    " 'class_threshold', 'margin',]\n",
    "post_processed_metrics = compute_metric_lists(ROC_list, ROC_metric_list, False)[1:][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICxM9a1-xmqh"
   },
   "outputs": [],
   "source": [
    "#plot performance across 5 metrics for ROC, tuned and base random forests\n",
    "fig, axs = plt.subplots(1,5, figsize=(20,10))\n",
    "\n",
    "for i in range(len(metric_list)):\n",
    "    metric = metric_list[i]\n",
    "    ax = axs[i] \n",
    "    pcm = ax.boxplot([post_processed_metrics[metric],tuned_metrics[metric],repair_metrics[metric]],\n",
    "                   labels = ['PostProcessed Model', 'Tuned Model', 'repaired_model'])\n",
    "    #ax.title.set_text('Eta level vs ' + metric)\n",
    "    ax.set_ylabel(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJ5pYCaAxooN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW_DS_GA_1017_jg6615",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
